{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e35043-4be1-475c-a1b0-fc7fbf4b899f",
   "metadata": {},
   "source": [
    "### Procedure for Training ResNet-18 on CIFAR100  \n",
    "\n",
    "To train ResNet-18 on the CIFAR100 dataset using PyTorch, some modifications are necessary because the ResNet-18 model provided by PyTorch is designed for the ImageNet dataset. Below, we outline the required steps to adapt ResNet-18 for CIFAR100 and ensure compatibility with AdaPT.  \n",
    "\n",
    "#### Understanding the Model Modifications  \n",
    "\n",
    "1. **Image Dimensions:**  \n",
    "   - The ResNet-18 model for ImageNet is designed for images with dimensions of $(7 \\times 7)$.  \n",
    "   - CIFAR10 and CIFAR100 images are $(3 \\times 3)$. Therefore, we must modify the first convolutional layer to handle this difference.\n",
    "\n",
    "2. **Output Classes:**  \n",
    "   - ImageNet has 1000 classes, so the final fully connected (FC) layer in ResNet-18 has 1000 neurons.  \n",
    "   - CIFAR10 and CIFAR100 have 10 and 100 classes, respectively. Thus, the FC layer must be updated accordingly.\n",
    "\n",
    "#### Step-by-Step Procedure  \n",
    "\n",
    "1. **Loading and Modifying the Pretrained ResNet-18 Model:**  \n",
    "   - Start by loading the ResNet-18 model provided by PyTorch, which is pretrained on ImageNet.  \n",
    "   - Modify the model for CIFAR10:\n",
    "     - Adjust the first convolutional layer to handle $(3 \\times 3)$ input images.  \n",
    "     - Change the final FC layer to output 10 classes.  \n",
    "\n",
    "2. **Ensuring Compatibility with AdaPT:**  \n",
    "   - To ensure the final ResNet-18 model is compatible with AdaPT, we will use the pretrained ResNet-18 weights for CIFAR10 that are already available in AdaPT (`resnet18.pt`).\n",
    "   - Place the `resnet18.pt` state dictionary file in the same directory as your training code.  \n",
    "   - Load the state dictionary from AdaPT (`resnet18.pt`) and apply it to the modified ResNet-18 model for CIFAR10.  \n",
    "   - This ensures the ResNet-18 model is compatible with AdaPT's framework and can be further adapted for CIFAR100.\n",
    "\n",
    "3. **Converting the Model to CIFAR100:**   \n",
    "   - Modify the FC layer once more to output 100 classes, adapting the model for CIFAR100.\n",
    "\n",
    "4. **Final Preparation:**  \n",
    "   - The CIFAR100-compatible model is now ready for training on the CIFAR100 dataset.  \n",
    "   - Save the trained model's weights as a `.pt` file, which can then be used for evaluation with AdaPT.  \n",
    "\n",
    "#### Key Notes:  \n",
    "- The adjustments to the FC layer must match the number of classes in the dataset being used (10 for CIFAR10 and 100 for CIFAR100).  \n",
    "- Make sure the model is saved in a format that maintains compatibility with AdaPT.  \n",
    "\n",
    "This process ensures that ResNet-18 is properly adapted to CIFAR100 while remaining compatible with the AdaPT framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6f741-0754-497e-990f-6186167fae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch import nn, optim\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Step 1: Load and Preprocess CIFAR-100 Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))  # CIFAR-100 mean and std\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-100 train and test datasets\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the state_dict\n",
    "state_dict = torch.load(\"resnet18.pt\")\n",
    "\n",
    "# Initialize a ResNet18 model\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "# Modify the first convolution layer (conv1) to match the saved model (3x3 kernel)\n",
    "model.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "# Modify the fc layer to match CIFAR10 (10 classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# Load the state_dict into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Now modify the fc layer for CIFAR100 (100 classes)\n",
    "num_classes = 100\n",
    "in_features = model.fc.in_features  # Get the input features of the fc layer\n",
    "model.fc = nn.Linear(in_features, num_classes)  # Replace the fc layer\n",
    "model = model.to(device)  # Move the model to the same device as the inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db7254-d8e9-467a-9bb5-a2149bf736a7",
   "metadata": {},
   "source": [
    "### Step 2: Training on CIFAR100  \n",
    "\n",
    "In this step, we begin training the ResNet-18 model on the CIFAR100 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b888390-2c31-4eba-a0d6-9807f1b71400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Loss Function, Optimizer, and Learning Rate Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Step 4: Training Function\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Step 5: Evaluation Function\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Step 6: Train and Evaluate the Model\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "# Step 7: Save the Model Weights\n",
    "torch.save(model.state_dict(), 'resnet18cifar100.pt')\n",
    "print(\"Model weights saved to resnet18cifar100.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
